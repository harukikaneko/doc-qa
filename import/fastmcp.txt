次のコマンドを実行すると、このサーバーをClaude Desktopにインストールしてすぐに操作することができます。

fastmcp install server.py
MCP検査官

コアコンセプト
これらは、使い慣れたデコレータベースのアプローチを使用して MCP サーバーを作成するための構成要素です。

サーバーFastMCP​
MCPアプリケーションを表す中心オブジェクト。接続、プロトコルの詳細、ルーティングを処理します。

from fastmcp import FastMCP

# Create a named server
mcp = FastMCP("My App")

# Specify dependencies needed when deployed via `fastmcp install`
mcp = FastMCP("My App", dependencies=["pandas", "numpy"])
ツール
ツールを使用すると、LLMはPython関数を実行することでアクションを実行できます。計算、外部API呼び出し、または副作用を伴うタスクに最適です。

同期関数または非同期関数を で装飾します@mcp.tool()。FastMCP は、型ヒントとドキュメント文字列に基づいて必要な MCP スキーマを自動生成します。複雑な入力には Pydantic モデルを使用できます。

import httpx
from pydantic import BaseModel

class UserInfo(BaseModel):
    user_id: int
    notify: bool = False

@mcp.tool()
async def send_notification(user: UserInfo, message: str) -> dict:
    """Sends a notification to a user if requested."""
    if user.notify:
        # Simulate sending notification
        print(f"Notifying user {user.user_id}: {message}")
        return {"status": "sent", "user_id": user.user_id}
    return {"status": "skipped", "user_id": user.user_id}

@mcp.tool()
def get_stock_price(ticker: str) -> float:
    """Gets the current price for a stock ticker."""
    # Replace with actual API call
    prices = {"AAPL": 180.50, "GOOG": 140.20}
    return prices.get(ticker.upper(), 0.0)
リソース
リソースはLLMにデータを公開します。リソースは主に、大きな計算や副作用（GETリクエストなど）を伴わない情報を提供する必要があります。

関数を で装飾します@mcp.resource("your://uri")。URI 内で中括弧を使用して、{}URI の一部が関数のパラメータとなる動的リソース (テンプレート) を定義します。

# Static resource returning simple text
@mcp.resource("config://app-version")
def get_app_version() -> str:
    """Returns the application version."""
    return "v2.1.0"

# Dynamic resource template expecting a 'user_id' from the URI
@mcp.resource("db://users/{user_id}/email")
async def get_user_email(user_id: str) -> str:
    """Retrieves the email address for a given user ID."""
    # Replace with actual database lookup
    emails = {"123": "alice@example.com", "456": "bob@example.com"}
    return emails.get(user_id, "not_found@example.com")

# Resource returning JSON data
@mcp.resource("data://product-categories")
def get_categories() -> list[str]:
    """Returns a list of available product categories."""
    return ["Electronics", "Books", "Home Goods"]
プロンプト
プロンプトは、LLMの再利用可能なテンプレートまたはインタラクションパターンを定義します。これにより、LLMはサーバーの機能を効果的に活用できるようになります。

関数を で装飾します@mcp.prompt()。この関数は、必要なプロンプト コンテンツを返す必要があります。プロンプト コンテンツは、単純な文字列、Messageオブジェクト (UserMessageや などAssistantMessage)、またはこれらのリストのいずれかになります。

from fastmcp.prompts.base import UserMessage, AssistantMessage

@mcp.prompt()
def ask_review(code_snippet: str) -> str:
    """Generates a standard code review request."""
    return f"Please review the following code snippet for potential bugs and style issues:\n```python\n{code_snippet}\n```"

@mcp.prompt()
def debug_session_start(error_message: str) -> list[Message]:
    """Initiates a debugging help session."""
    return [
        UserMessage(f"I encountered an error:\n{error_message}"),
        AssistantMessage("Okay, I can help with that. Can you provide the full traceback and tell me what you were trying to do?")
    ]
コンテクスト
でタイプヒントされたパラメータを追加することで、ツールまたはリソース関数内でMCP サーバー機能にアクセスできるようになりますfastmcp.Context。

from fastmcp import Context, FastMCP

mcp = FastMCP("Context Demo")

@mcp.resource("system://status")
async def get_system_status(ctx: Context) -> dict:
    """Checks system status and logs information."""
    await ctx.info("Checking system status...")
    # Perform checks
    await ctx.report_progress(1, 1) # Report completion
    return {"status": "OK", "load": 0.5, "client": ctx.client_id}

@mcp.tool()
async def process_large_file(file_uri: str, ctx: Context) -> str:
    """Processes a large file, reporting progress and reading resources."""
    await ctx.info(f"Starting processing for {file_uri}")
    # Read the resource using the context
    file_content_resource = await ctx.read_resource(file_uri)
    file_content = file_content_resource[0].content # Assuming single text content
    lines = file_content.splitlines()
    total_lines = len(lines)

    for i, line in enumerate(lines):
        # Process line...
        if (i + 1) % 100 == 0: # Report progress every 100 lines
            await ctx.report_progress(i + 1, total_lines)

    await ctx.info(f"Finished processing {file_uri}")
    return f"Processed {total_lines} lines."
オブジェクトContextは以下を提供します:

ログ記録: ctx.debug()、、、ctx.info()ctx.warning()ctx.error()
進捗報告:ctx.report_progress(current, total)
リソース アクセス:await ctx.read_resource(uri)
リクエスト情報: ctx.request_id、ctx.client_id
サンプリング (詳細):await ctx.sample(...)接続された LLM クライアントに補完を要求します。
画像
ヘルパー クラスを使用して、画像の入出力を簡単に処理しますfastmcp.Image。

from fastmcp import FastMCP, Image
from PIL import Image as PILImage
import io

mcp = FastMCP("Image Demo")

@mcp.tool()
def create_thumbnail(image_data: Image) -> Image:
    """Creates a 100x100 thumbnail from the provided image."""
    img = PILImage.open(io.BytesIO(image_data.data)) # Assumes image_data received as Image with bytes
    img.thumbnail((100, 100))
    buffer = io.BytesIO()
    img.save(buffer, format="PNG")
    # Return a new Image object with the thumbnail data
    return Image(data=buffer.getvalue(), format="png")

@mcp.tool()
def load_image_from_disk(path: str) -> Image:
    """Loads an image from the specified path."""
    # Handles reading file and detecting format based on extension
    return Image(path=path)
FastMCP は、MCP プロトコルに必要な base64 エンコード形式との間の変換を処理します。

MCPクライアント
このClientクラスを使用すると、Python コードから任意の MCP サーバー (FastMCP サーバーに限らない) と対話できます。

from fastmcp import Client

async with Client("path/to/server") as client:
    # Call a tool
    result = await client.call_tool("weather", {"location": "San Francisco"})
    print(result)
    
    # Read a resource
    res = await client.read_resource("db://users/123/profile")
    print(res)
サポートされている任意のトランスポートプロトコル（Stdio、SSE、FastMCPなど）を使用してサーバーに接続できます。トランスポートを指定しない場合は、Clientクラスが接続文字列またはサーバーオブジェクトから適切なトランスポートを自動的に検出します。

クライアントメソッド
このClientクラスは、MCP サーバーと対話するためのいくつかのメソッドを公開します。

async with Client("path/to/server") as client:
    # List available tools
    tools = await client.list_tools()
    
    # List available resources
    resources = await client.list_resources()
    
    # Call a tool with arguments
    result = await client.call_tool("generate_report", {"user_id": 123})
    
    # Read a resource
    user_data = await client.read_resource("db://users/123/profile")
        
    # Get a prompt
    greeting = await client.get_prompt("welcome", {"name": "Alice"})
    
    # Send progress updates
    await client.progress("task-123", 50, 100)  # 50% complete
    
    # Basic connectivity testing
    await client.ping()
これらのメソッドは MCP プロトコル操作に直接対応しているため、MCP 互換サーバー (FastMCP サーバーだけでなく) との対話が容易になります。

交通手段
FastMCP は、MCP サーバーに接続するためのさまざまなトランスポート プロトコルをサポートしています。

from fastmcp import Client
from fastmcp.client.transports import (
    SSETransport, 
    PythonStdioTransport, 
    FastMCPTransport
)

# Connect to a server over SSE (common for web-based MCP servers)
async with Client(SSETransport("http://localhost:8000/mcp")) as client:
    # Use client here...

# Connect to a Python script using stdio (useful for local tools)
async with Client(PythonStdioTransport("path/to/script.py")) as client:
    # Use client here...

# Connect directly to a FastMCP server object in the same process
from your_app import mcp_server
async with Client(FastMCPTransport(mcp_server)) as client:
    # Use client here...
一般的な交通手段の選択肢は次のとおりです。

SSETransport: Server-Sent Events (HTTP) 経由でサーバーに接続する
PythonStdioTransport: Pythonスクリプトを実行し、stdio経由で通信する
FastMCPTransport: FastMCPサーバーオブジェクトに直接接続する
WSTransport: WebSocket経由で接続
さらに、接続文字列またはFastMCPサーバー オブジェクトをClientコンストラクターに渡すと、適切なトランスポートが自動的に検出されます。

LLMサンプリング
サンプリングは、サーバーがクライアント LLM から完了を要求できるようにする MCP 機能であり、サーバーのセキュリティとプライバシーを維持しながら高度なユースケースを可能にします。

import marvin  # Or any other LLM client
from fastmcp import Client, Context, FastMCP
from fastmcp.client.sampling import RequestContext, SamplingMessage, SamplingParams

# -- SERVER SIDE --
# Create a server that requests LLM completions from the client

mcp = FastMCP("Sampling Example")

@mcp.tool()
async def generate_poem(topic: str, context: Context) -> str:
    """Generate a short poem about the given topic."""
    # The server requests a completion from the client LLM
    response = await context.sample(
        f"Write a short poem about {topic}",
        system_prompt="You are a talented poet who writes concise, evocative verses."
    )
    return response.text

@mcp.tool()
async def summarize_document(document_uri: str, context: Context) -> str:
    """Summarize a document using client-side LLM capabilities."""
    # First read the document as a resource
    doc_resource = await context.read_resource(document_uri)
    doc_content = doc_resource[0].content  # Assuming single text content
    
    # Then ask the client LLM to summarize it
    response = await context.sample(
        f"Summarize the following document:\n\n{doc_content}",
        system_prompt="You are an expert summarizer. Create a concise summary."
    )
    return response.text

# -- CLIENT SIDE --
# Create a client that handles the sampling requests

async def sampling_handler(
    messages: list[SamplingMessage],
    params: SamplingParams,
    ctx: RequestContext,
) -> str:
    """Handle sampling requests from the server using your preferred LLM."""
    # Extract the messages and system prompt
    prompt = [m.content.text for m in messages if m.content.type == "text"]
    system_instruction = params.systemPrompt or "You are a helpful assistant."
    
    # Use your preferred LLM client to generate completions
    return await marvin.say_async(
        message=prompt,
        instructions=system_instruction,
    )

# Connect them together
async with Client(mcp, sampling_handler=sampling_handler) as client:
    result = await client.call_tool("generate_poem", {"topic": "autumn leaves"})
    print(result.content[0].text)
このパターンが強力な理由は次のとおりです:

サーバーはテキスト生成をクライアントLLMに委任できる
サーバーはビジネスロジックとデータ処理に重点を置きます
クライアントは、どのLLMが使用されるか、リクエストがどのように処理されるかを制御します。
機密データを外部APIに送信する必要はありません
ルーツアクセス
FastMCPはMCPルート機能を公開しており、クライアントはアクセスできるファイルシステムのルートを指定できます。これにより、ファイル操作を必要とするツールのための安全な境界が確保されます。サーバーはクライアントのルートを明示的に考慮する必要があることに注意してください。

from fastmcp import Client, RootsList

# Specify file roots that the client can access
roots = ["file:///path/to/allowed/directory"]

async with Client(mcp_server, roots=roots) as client:
    # Now tools in the MCP server can access files in the specified roots
    await client.call_tool("process_file", {"filename": "data.csv"})
高度な機能
FastMCP v2 では、コアコンセプトを基に、より複雑なシナリオに対応する強力な機能を導入しています。

プロキシサーバー
仲介役として機能し、リクエストを別の MCP エンドポイント (サーバーまたは別のクライアント接続) にプロキシする FastMCP サーバーを作成します。

ユースケース:

トランスポート変換: Stdio で実行されているサーバー (多くのローカル ツールと同様) を SSE または WebSocket 経由で公開し、Web クライアントまたは Claude Desktop からアクセスできるようにします。
機能の追加:既存のサーバーをラップして、認証、リクエストのログ記録、またはツールの動作の変更を追加します。
サーバーの集約:複数のバックエンド MCP サーバーを単一のプロキシ インターフェイスの背後に結合します (ただし、mountこの方が簡単かもしれません)。
import asyncio
from fastmcp import FastMCP, Client
from fastmcp.client.transports import PythonStdioTransport

# Create a client that connects to the original server
proxy_client = Client(
    transport=PythonStdioTransport('path/to/original_stdio_server.py'),
)

# Create a proxy server that connects to the client and exposes its capabilities
proxy = FastMCP.from_client(proxy_client, name="Stdio-to-SSE Proxy")

if __name__ == "__main__":
    proxy.run(transport='sse')
FastMCP.from_clientターゲットに接続し、その機能を検出し、プロキシ サーバー インスタンスを動的に構築するクラス メソッドです。

MCPサーバーの構成
モジュール型のFastMCPサーバーを作成し、親サーバーに「マウント」することで、より大規模なMCPアプリケーションを構築できます。これにより、ツール名とリソースURIのプレフィックスが自動的に処理され、競合を回避できます。

from fastmcp import FastMCP

# --- Weather MCP ---
weather_mcp = FastMCP("Weather Service")

@weather_mcp.tool()
def get_forecast(city: str): 
    return f"Sunny in {city}"

@weather_mcp.resource("data://temp/{city}")
def get_temp(city: str): 
    return 25.0

# --- News MCP ---
news_mcp = FastMCP("News Service")

@news_mcp.tool()
def fetch_headlines():
    return ["Big news!", "Other news"]

@news_mcp.resource("data://latest_story")
def get_story():
    return "A story happened."

# --- Composite MCP ---

mcp = FastMCP("Composite")

# Mount sub-apps with prefixes
mcp.mount("weather", weather_mcp) # Tools prefixed "weather/", resources prefixed "weather+"
mcp.mount("news", news_mcp)       # Tools prefixed "news/", resources prefixed "news+"

@mcp.tool()
def ping(): 
    return "Composite OK"


if __name__ == "__main__":
    mcp.run()
これにより、複雑な MCP システムのコード編成と再利用性が促進されます。

OpenAPIとFastAPIの生成
既存の Web API を活用して、そこから FastMCP サーバーを自動的に生成します。

デフォルトでは、次のルールが適用されます。

GETリクエスト -> MCP リソース
GETパスパラメータ付きのリクエスト -> MCP リソーステンプレート
その他すべてのHTTPメソッド -> MCPツール
これらのルールをオーバーライドして、特定のエンドポイントをカスタマイズしたり、無視したりすることもできます。

FastAPIから:

from fastapi import FastAPI
from fastmcp import FastMCP

# Your existing FastAPI application
fastapi_app = FastAPI(title="My Existing API")

@fastapi_app.get("/status")
def get_status(): 
    return {"status": "running"}

@fastapi_app.post("/items")
def create_item(name: str, price: float): 
    return {"id": 1, "name": name, "price": price}

# Generate an MCP server directly from the FastAPI app
mcp_server = FastMCP.from_fastapi(fastapi_app)

if __name__ == "__main__":
    mcp_server.run()
OpenAPI 仕様より:

import httpx
import json
from fastmcp import FastMCP

# Load the OpenAPI spec (dict)
# with open("my_api_spec.json", "r") as f:
#     openapi_spec = json.load(f)
openapi_spec = { ... } # Your spec dict

# Create an HTTP client to make requests to the actual API endpoint
http_client = httpx.AsyncClient(base_url="https://api.yourservice.com")

# Generate the MCP server
mcp_server = FastMCP.from_openapi(openapi_spec, client=http_client)

if __name__ == "__main__":
    mcp_server.run()
サーバーの実行
ニーズに最適な方法を選択してください:

開発モード（ビルドとテストに推奨）
fastmcp devMCP Inspector を使用した対話型テスト環境に使用します。

fastmcp dev your_server_file.py
# With temporary dependencies
fastmcp dev your_server_file.py --with pandas --with numpy
# With local package in editable mode
fastmcp dev your_server_file.py --with-editable .
Claude デスクトップ統合（通常使用向け）
Claudeデスクトップアプリ内で永続的に使用できるようにサーバーをセットアップするために使用しますfastmcp install。を使用して分離された環境を作成しますuv。

fastmcp install your_server_file.py
# With a custom name in Claude
fastmcp install your_server_file.py --name "My Analysis Tool"
# With extra packages and environment variables
fastmcp install server.py --with requests -v API_KEY=123 -f .env
直接実行（高度なユースケース向け）
Claude の外部でカスタムデプロイメントや統合を行う場合は、サーバースクリプトを直接実行します。環境と依存関係はお客様自身で管理します。

に追加するyour_server_file.py:

if __name__ == "__main__":
    mcp.run() # Assuming 'mcp' is your FastMCP instance
実行:

python your_server_file.py
# or
uv run python your_server_file.py
サーバーオブジェクト名
FastMCPインスタンスの名前がmcp、server、または ではない場合は、およびコマンドの構文appを使用して指定します。file:objectdevinstall

fastmcp dev my_module.py:my_mcp_instance
fastmcp install api.py:api_app
例
examples/さまざまな機能を示すコード サンプルのディレクトリを調べてください。

simple_echo.py: 基本的なツール、リソース、およびプロンプト。
complex_inputs.py: ツール入力に Pydantic モデルを使用します。
mount_example.py: 複数の FastMCP サーバーをマウントします。
sampling.py: MCP サーバー内で LLM 補完を使用する。
screenshot.py: Image オブジェクトを返すツール。
text_me.py: 外部 API と対話するツール。
memory.py: データベースとのやりとりを伴うより複雑な例。
貢献
貢献はオープンソースコミュニティを活性化させます！改善や機能追加を歓迎します。

オープン開発者ガイド